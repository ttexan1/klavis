{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klavis-ai/klavis/blob/main/examples/openai/Use_Klavis_with_OpenAI.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# OpenAI + Klavis AI Integration\n",
        "\n",
        "This tutorial demonstrates how to use OpenAI function calling with Klavis MCP (Model Context Protocol) servers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "- **OpenAI API key** - Get at [openai.com](https://openai.com/)\n",
        "- **Klavis API key** - Get at [klavis.ai](https://klavis.ai/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install the required packages\n",
        "%pip install -qU openai klavis requests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from klavis import Klavis\n",
        "from klavis.types import McpServerName, ConnectionType, ToolFormat\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"  # Replace with your actual OpenAI API key\n",
        "os.environ[\"KLAVIS_API_KEY\"] = \"YOUR_KLAVIS_API_KEY\"  # Replace with your actual Klavis API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Case Study 1 : OpenAI + YouTube MCP Server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "#### Step 1 - Create YouTube MCP Server using Klavis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "klavis_client = Klavis(api_key=os.getenv(\"KLAVIS_API_KEY\"))\n",
        "\n",
        "youtube_mcp_instance = klavis_client.mcp_server.create_server_instance(\n",
        "    server_name=McpServerName.YOUTUBE,\n",
        "    user_id=\"1234\",\n",
        "    platform_name=\"Klavis\",\n",
        "    connection_type=ConnectionType.STREAMABLE_HTTP,\n",
        ")\n",
        "\n",
        "# print(f\"üîó YouTube MCP server created at: {youtube_mcp_instance.server_url}, and the instance id is {youtube_mcp_instance.instance_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "#### Step 2 - Create general method to use MCP Server with OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def openai_with_mcp_server(mcp_server_url: str, user_query: str):\n",
        "    openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Use the available tools to answer the user's question.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"{user_query}\"}\n",
        "    ]\n",
        "    \n",
        "    mcp_server_tools = klavis_client.mcp_server.list_tools(\n",
        "        server_url=mcp_server_url,\n",
        "        connection_type=ConnectionType.STREAMABLE_HTTP,\n",
        "        format=ToolFormat.OPENAI,\n",
        "    )\n",
        "    \n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages,\n",
        "        tools=mcp_server_tools.tools\n",
        "    )\n",
        "    \n",
        "    messages.append(response.choices[0].message)\n",
        "\n",
        "    if response.choices[0].message.tool_calls:\n",
        "        for tool_call in response.choices[0].message.tool_calls:\n",
        "            function_name = tool_call.function.name\n",
        "            function_args = json.loads(tool_call.function.arguments)\n",
        "            \n",
        "            print(f\"üîß Calling: {function_name}, with args: {function_args}\")\n",
        "            \n",
        "            result = klavis_client.mcp_server.call_tools(\n",
        "                server_url=mcp_server_url,\n",
        "                tool_name=function_name,\n",
        "                tool_args=function_args,\n",
        "                connection_type=ConnectionType.STREAMABLE_HTTP\n",
        "            )\n",
        "            \n",
        "            messages.append({\n",
        "                \"role\": \"tool\",\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"content\": str(result)\n",
        "            })\n",
        "            \n",
        "    final_response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages\n",
        "    )\n",
        "    \n",
        "    return final_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 3 - Summarize your favorite video! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Calling: get_youtube_video_transcript, with args: {'url': 'https://www.youtube.com/watch?v=LCEmiRjPEtQ'}\n",
            "The YouTube video titled \"Andrej Karpathy: Software Is Changing (Again)\" features a keynote by Andrej Karpathy at the AI Startup School in San Francisco. The video discusses the evolution of software and introduces the concept of \"Software 3.0,\" where natural language processing becomes a new interface for programming.\n",
            "\n",
            "### Summary of Key Points:\n",
            "\n",
            "- **00:00 - Intro**: Karpathy introduces the topic of evolving software.\n",
            "  \n",
            "- **01:25 - Software evolution: From 1.0 to 3.0**: Acknowledges that software has undergone significant changes, leading to the current phase of Software 3.0.\n",
            "\n",
            "- **04:40 - Programming in English: Rise of Software 3.0**: Discusses how programming is becoming more accessible with natural language, allowing users to interact with systems in English.\n",
            "\n",
            "- **06:10 - LLMs as utilities, fabs, and operating systems**: Highlights the role of Large Language Models (LLMs) as essential utilities in modern software.\n",
            "\n",
            "- **11:04 - The new LLM OS and historical computing analogies**: Compares the current state of LLMs to earlier computing eras, suggesting a transformative impact.\n",
            "\n",
            "- **14:39 - Psychology of LLMs: People spirits and cognitive quirks**: Mentions that LLMs reflect human-like characteristics and quirks since they are trained on human data.\n",
            "\n",
            "- **18:22 - Designing LLM apps with partial autonomy**: Explores how new applications can leverage LLMs' capabilities and partial autonomy.\n",
            "\n",
            "- **23:40 - The importance of human-AI collaboration loops**: Emphasizes the need for collaborative systems between humans and AI.\n",
            "\n",
            "- **26:00 - Lessons from Tesla Autopilot & autonomy sliders**: Shares insights from Tesla's experience with autonomous systems.\n",
            "\n",
            "- **27:52 - The Iron Man analogy: Augmentation vs. agents**: Uses the Iron Man analogy to differentiate between user augmentation and fully autonomous agents.\n",
            "\n",
            "- **29:06 - Vibe Coding: Everyone is now a programmer**: Hacks into the notion that traditional programming barriers are lowering, making programming accessible to more people.\n",
            "\n",
            "- **33:39 - Building for agents: Future-ready digital infrastructure**: Discusses the need for infrastructure that can support the integration of LLMs as central components.\n",
            "\n",
            "- **38:14 - Summary: We‚Äôre in the 1960s of LLMs ‚Äî time to build**: Concludes that we are at a pivotal moment in LLM development, akin to the early days of computing.\n",
            "\n",
            "### Conclusion:\n",
            "Karpathy argues that we are experiencing a fundamental shift in how software operates, driven largely by the rise of LLMs and their integration into everyday applications. This change signifies a new era where programming becomes more conversational, making technology more accessible.\n"
          ]
        }
      ],
      "source": [
        "YOUTUBE_VIDEO_URL = \"https://www.youtube.com/watch?v=LCEmiRjPEtQ\"  # pick a video you like!\n",
        "\n",
        "result = openai_with_mcp_server(\n",
        "    mcp_server_url=youtube_mcp_instance.server_url, \n",
        "    user_query=f\"Please provide a complete summary of this YouTube video with timestamp: {YOUTUBE_VIDEO_URL}\"\n",
        ")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "‚úÖ Great! You've successfully created an AI agent that uses OpenAI function calling with Klavis MCP servers to summarize YouTube videos!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Case Study 2 : OpenAI + Gmail MCP Server (OAuth needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîê Opening OAuth authorization for Gmail, if you are not redirected, please open the following URL in your browser: https://api.klavis.ai/oauth/gmail/authorize?instance_id=d9d482b3-433a-4330-9a8b-9548c0b0a326\n"
          ]
        }
      ],
      "source": [
        "import webbrowser\n",
        "\n",
        "gmail_mcp_server = klavis_client.mcp_server.create_server_instance(\n",
        "    server_name=McpServerName.GMAIL,\n",
        "    user_id=\"1234\",\n",
        "    platform_name=\"Klavis\",\n",
        "    connection_type=ConnectionType.STREAMABLE_HTTP,\n",
        ")\n",
        "\n",
        "webbrowser.open(gmail_mcp_server.oauth_url)\n",
        "\n",
        "print(f\"üîê Opening OAuth authorization for Gmail, if you are not redirected, please open the following URL in your browser: {gmail_mcp_server.oauth_url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Calling: send_email, with args: {'to': ['zihaolin@klavis.ai'], 'subject': 'Test OpenAI + Gmail MCP Server', 'body': 'Hello World'}\n",
            "The email has been successfully sent to zihaolin@klavis.ai with the subject \"Test OpenAI + Gmail MCP Server\" and the body \"Hello World.\"\n"
          ]
        }
      ],
      "source": [
        "EMAIL_RECIPIENT = \"zihaolin@klavis.ai\" # Replace with your email\n",
        "EMAIL_SUBJECT = \"Test OpenAI + Gmail MCP Server\"\n",
        "EMAIL_BODY = \"Hello World\"\n",
        "\n",
        "result = openai_with_mcp_server(\n",
        "    mcp_server_url=gmail_mcp_server.server_url, \n",
        "    user_query=f\"Please send an email to {EMAIL_RECIPIENT} with subject {EMAIL_SUBJECT} and body {EMAIL_BODY}\"\n",
        ")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This tutorial demonstrated how to integrate OpenAI's function calling capabilities with Klavis MCP servers to create powerful AI applications. We covered two practical examples:\n",
        "\n",
        "**üé• YouTube Integration**: Built an AI assistant that can automatically summarize YouTube videos by extracting transcripts and providing detailed, timestamped summaries.\n",
        "\n",
        "**üìß Gmail Integration**: Created an AI-powered email assistant that can send emails through Gmail with OAuth authentication.\n",
        "\n",
        "### Key Takeaways:\n",
        "- **Easy Setup**: Klavis MCP servers can be created with just a few lines of code\n",
        "- **OpenAI Compatible**: All tools are formatted for seamless OpenAI function calling\n",
        "- **Versatile**: Support for both simple APIs (YouTube) and OAuth-authenticated services (Gmail)\n",
        "- **Scalable**: The same pattern can be applied to any of the MCP servers available in Klavis\n",
        "\n",
        "**Happy building!** üöÄ\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
