{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klavis-ai/klavis/blob/main/examples/openai/Use_Klavis_with_OpenAI.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# OpenAI + Klavis AI Integration\n",
        "\n",
        "This tutorial demonstrates how to use OpenAI function calling with Klavis MCP (Model Context Protocol) servers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "- **OpenAI API key** - Get at [openai.com](https://openai.com/)\n",
        "- **Klavis API key** - Get at [klavis.ai](https://klavis.ai/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install the required packages\n",
        "%pip install -qU openai klavis requests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from klavis import Klavis\n",
        "from klavis.types import McpServerName, ConnectionType, ToolFormat\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"  # Replace with your actual OpenAI API key\n",
        "os.environ[\"KLAVIS_API_KEY\"] = \"YOUR_KLAVIS_API_KEY\"  # Replace with your actual Klavis API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Case Study 1 : OpenAI + YouTube MCP Server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "#### Step 1 - Create YouTube MCP Server using Klavis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "klavis_client = Klavis(api_key=os.getenv(\"KLAVIS_API_KEY\"))\n",
        "\n",
        "youtube_mcp_instance = klavis_client.mcp_server.create_server_instance(\n",
        "    server_name=McpServerName.YOUTUBE,\n",
        "    user_id=\"1234\",\n",
        "    platform_name=\"Klavis\",\n",
        "    connection_type=ConnectionType.STREAMABLE_HTTP,\n",
        ")\n",
        "\n",
        "# print(f\"üîó YouTube MCP server created at: {youtube_mcp_instance.server_url}, and the instance id is {youtube_mcp_instance.instance_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "#### Step 2 - Create general method to use MCP Server with OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def openai_with_mcp_server(mcp_server_url: str, user_query: str):\n",
        "    openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Use the available tools to answer the user's question.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"{user_query}\"}\n",
        "    ]\n",
        "    \n",
        "    mcp_server_tools = klavis_client.mcp_server.list_tools(\n",
        "        server_url=mcp_server_url,\n",
        "        connection_type=ConnectionType.STREAMABLE_HTTP,\n",
        "        format=ToolFormat.OPENAI,\n",
        "    )\n",
        "    \n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages,\n",
        "        tools=mcp_server_tools.tools\n",
        "    )\n",
        "    \n",
        "    messages.append(response.choices[0].message)\n",
        "\n",
        "    if response.choices[0].message.tool_calls:\n",
        "        for tool_call in response.choices[0].message.tool_calls:\n",
        "            function_name = tool_call.function.name\n",
        "            function_args = json.loads(tool_call.function.arguments)\n",
        "            \n",
        "            print(f\"üîß Calling: {function_name}, with args: {function_args}\")\n",
        "            \n",
        "            result = klavis_client.mcp_server.call_tools(\n",
        "                server_url=mcp_server_url,\n",
        "                tool_name=function_name,\n",
        "                tool_args=function_args,\n",
        "                connection_type=ConnectionType.STREAMABLE_HTTP\n",
        "            )\n",
        "            \n",
        "            messages.append({\n",
        "                \"role\": \"tool\",\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"content\": result.result.content[0]['text']\n",
        "            })\n",
        "            \n",
        "    final_response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages\n",
        "    )\n",
        "    \n",
        "    return final_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 3 - Summarize your favorite video! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Calling: get_youtube_video_transcript, with args: {'url': 'https://www.youtube.com/watch?v=LCEmiRjPEtQ'}\n",
            "The video titled \"Andrej Karpathy: Software Is Changing (Again)\" features a keynote by Andrej Karpathy presented at the AI Startup School in San Francisco. The talk discusses the evolution of software, focusing on the transition to what he calls \"Software 3.0,\" where natural language becomes a primary interface for programming. Here‚Äôs a detailed summary based on timestamps:\n",
            "\n",
            "- **00:00 - Intro**: Karpathy introduces the topic of software evolution and its current state.\n",
            "\n",
            "- **01:25 - Software evolution: From 1.0 to 3.0**: He outlines the historical progress of software from version 1.0 to 3.0, emphasizing significant shifts.\n",
            "\n",
            "- **04:40 - Programming in English: Rise of Software 3.0**: Discusses how the introduction of large language models (LLMs) allows programming using natural language, making it more accessible.\n",
            "\n",
            "- **06:10 - LLMs as utilities, fabs, and operating systems**: Karpathy likens LLMs to utilities and operating systems, discussing their growing importance in the software ecosystem.\n",
            "\n",
            "- **11:04 - The new LLM OS and historical computing analogies**: He draws parallels between current LLM technology and past computing developments, suggesting we are akin to the 1960s in our understanding and utilization of LLMs.\n",
            "\n",
            "- **14:39 - Psychology of LLMs: People spirits and cognitive quirks**: Examines the nature of LLMs as simulations that possess emergent psychological traits akin to humans.\n",
            "\n",
            "- **18:22 - Designing LLM apps with partial autonomy**: Discusses the potential for creating applications that integrate LLMs with a degree of autonomy.\n",
            "\n",
            "- **23:40 - The importance of human-AI collaboration loops**: Emphasizes the necessity of building effective collaboration between humans and AI.\n",
            "\n",
            "- **26:00 - Lessons from Tesla Autopilot & autonomy sliders**: He references his experiences at Tesla to illustrate lessons learned in achieving automation.\n",
            "\n",
            "- **27:52 - The Iron Man analogy: Augmentation vs. agents**: Compares tools like LLMs to Iron Man's suit, where humans are augmented rather than completely replaced.\n",
            "\n",
            "- **29:06 - Vibe Coding: Everyone is now a programmer**: Introduces the concept of \"vibe coding,\" where individuals can engage in programming through expressive, natural language inputs.\n",
            "\n",
            "- **33:39 - Building for agents: Future-ready digital infrastructure**: Advocates for designing digital infrastructure that is prepared for the rise of AI agents.\n",
            "\n",
            "- **38:14 - Summary: We‚Äôre in the 1960s of LLMs ‚Äî time to build**: Concludes by reinforcing the idea that we are just at the beginning of understanding and utilizing LLMs effectively.\n",
            "\n",
            "Throughout the talk, Karpathy leverages his experiences from Stanford, OpenAI, and Tesla to illustrate the transformative nature of LLMs in software development, indicating that we are on the cusp of a significant change in how software is created and interacted with. He encourages embracing this change and building the necessary infrastructure for a future intertwined with AI.\n"
          ]
        }
      ],
      "source": [
        "YOUTUBE_VIDEO_URL = \"https://www.youtube.com/watch?v=LCEmiRjPEtQ\"  # pick a video you like!\n",
        "\n",
        "result = openai_with_mcp_server(\n",
        "    mcp_server_url=youtube_mcp_instance.server_url, \n",
        "    user_query=f\"Please provide a complete summary of this YouTube video with timestamp: {YOUTUBE_VIDEO_URL}\"\n",
        ")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "‚úÖ Great! You've successfully created an AI agent that uses OpenAI function calling with Klavis MCP servers to summarize YouTube videos!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Case Study 2 : OpenAI + Gmail MCP Server (OAuth needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîê Opening OAuth authorization for Gmail, if you are not redirected, please open the following URL in your browser: https://api.klavis.ai/oauth/gmail/authorize?instance_id=d9d482b3-433a-4330-9a8b-9548c0b0a326\n"
          ]
        }
      ],
      "source": [
        "import webbrowser\n",
        "\n",
        "gmail_mcp_server = klavis_client.mcp_server.create_server_instance(\n",
        "    server_name=McpServerName.GMAIL,\n",
        "    user_id=\"1234\",\n",
        "    platform_name=\"Klavis\",\n",
        "    connection_type=ConnectionType.STREAMABLE_HTTP,\n",
        ")\n",
        "\n",
        "webbrowser.open(gmail_mcp_server.oauth_url)\n",
        "\n",
        "print(f\"üîê Opening OAuth authorization for Gmail, if you are not redirected, please open the following URL in your browser: {gmail_mcp_server.oauth_url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Calling: send_email, with args: {'to': ['zihaolin@klavis.ai'], 'subject': 'Test OpenAI + Gmail MCP Server', 'body': 'Hello World'}\n",
            "The email has been successfully sent to zihaolin@klavis.ai with the subject \"Test OpenAI + Gmail MCP Server\" and the body \"Hello World.\"\n"
          ]
        }
      ],
      "source": [
        "EMAIL_RECIPIENT = \"zihaolin@klavis.ai\" # Replace with your email\n",
        "EMAIL_SUBJECT = \"Test OpenAI + Gmail MCP Server\"\n",
        "EMAIL_BODY = \"Hello World\"\n",
        "\n",
        "result = openai_with_mcp_server(\n",
        "    mcp_server_url=gmail_mcp_server.server_url, \n",
        "    user_query=f\"Please send an email to {EMAIL_RECIPIENT} with subject {EMAIL_SUBJECT} and body {EMAIL_BODY}\"\n",
        ")\n",
        "\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
